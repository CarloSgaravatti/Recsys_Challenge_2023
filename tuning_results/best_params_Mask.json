{"learning_rate": 0.009588916735782473, "batch_size": 798, "dropout": 0.4947766195046696, "l2_reg": 0.0034925053698976944, "anneal_cap": 0.12147960521824828, "encoding_size": 50, "next_layer_size_multiplier": 3}