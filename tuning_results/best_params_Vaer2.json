{"n_layers": 1, "layer_1": 384, "learning_rate": 0.00026496901862762835, "batch_size": 32, "dropout": 0.5840758274263712, "l2_reg": 0.0002031869498246217, "anneal_cap": 0.025218322513711373, "total_anneal_steps": 68684}